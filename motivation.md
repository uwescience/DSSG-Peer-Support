---
layout: page
title: Project Motivation
---

**Questions**

Peer-support platforms are a popular option for young adults seeking out commiseration, advice, empathy, and general support as they navigate their lives. However, without the training and expertise that a licensed counselor would have, even the most well-intentioned individual on the platform may inadvertently offer feedback that is unhelpful or even damaging to a peer seeking support. In an effort to improve the effectiveness of these platforms, our project this summer will attempt to answer the question:

_What types of responses are the most helpful to individuals sharing their struggles in a peer support platform?_

**Background**

While traditional peer support has been offered through in-person interaction in small close knit communities, technology has enabled for the formation of online social networks of support on a much larger scale. Online peer support platforms now exist at the cusp of social networks and peer support groups. In such an environment, people can reach out with mental health concerns, to a larger group of peers experiencing similar challenges. However, like all solutions, new challenges are posed as a result. Peers on such platforms are not trained as counselors and may not always respond in ways that are helpful to those in need of support. Moderators and volunteers who are trained to ensure healthy engagement on the platform also lack a professional mental health background and could gain from effective feedback and improvements in their training. Conversations on these platforms often center around subjects that may be triggering to different individuals, and it is easy to inadvertently cause damage to another. Lastly, as with most social networks that allow for anonymity, there may be individuals on such platforms who pose as those with mental health challenges but actually exist on the platform for ulterior objectives.

Quantitatively understanding and measuring the help provided to individuals on such platforms, thus, becomes essential to helping them be healthy avenues for individuals seeking support. Insights from such work can guide the development of tools and training material for both platform users and volunteers, who frequently engage with those in need of support. Finally, we are hopeful that insights from our work can be extended to traditional mental health counselor training in a world that is constantly evolving in its engagement with technology.

**Stakeholders**

In any social networking platform, there are numerous stakeholders to consider. The first of course is the user of the platform. We believe users privacy and well-being. The second is the platform owner. We want to help improve aspects of the platform that will encourage convivial and friendly behavior but will not constrain a platform's ability to operate . 
Third, we are also considering how a platform may indirectly affect 

Finally, we recognize that the individuals who use these platforms are part of a larger community of friends and family. The potential impact on this community also looms significiantly in our mind.

The use  cases we are building for is identifying useful and helpful peer behavior. In an ideal state of the world, this tool  could be used as an asset for potential future researchers, platform administrations, and other platform owners to. We could envision these types of tools to identify the aggregate mental health of a platform. Further, these tools could potentially influence recommendation systems such that individuals seeking peer support could be matched with individuals who are most 

**Ethics**

There are numerous questions that we must address when considering how our work may ultimately impact users. We are examining data of individuals who are experiencing crisis and their privacy and well-being is amongst our highest priority. With respect to privacy, we have 

In order to understand the potential ethical ramifications of making adjustment to these platforms. We have consulted with existing crisis counselors, medical professionals, and with the owners of the platform. Part of this learning process  has told us that measuring  outcomes in individual well-being. 

Our project's focus is to identify words and behaviors that help people in crises. As part of these analyses, we put considerable weight into making sure that our models are interpretable and consistent with other practices in counseling and other mental health practices. One of the things that we think about is the potential ramifications of misidentifying behavior as either helpful or harmful. While our work currently does not influence behavior in a live environment, we realize that misclassification of behavior could potentially have serious downstream effects on a user's mental health and well-being. 
